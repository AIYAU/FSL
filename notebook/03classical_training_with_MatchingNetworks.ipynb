{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T09:39:31.230613Z",
     "start_time": "2024-06-23T09:39:31.212504Z"
    },
    "id": "gZ8bXCqpqno0",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "from pathlib import Path\n",
    "import random\n",
    "from statistics import mean\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T09:39:33.669527Z",
     "start_time": "2024-06-23T09:39:33.655426Z"
    },
    "id": "vpqXEWt8qno4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "random_seed = 0\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T09:39:38.509099Z",
     "start_time": "2024-06-23T09:39:36.650002Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3kYxNc4tqno7",
    "outputId": "85a76b58-4267-44dc-85fd-e9fff2243563",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from easyfsl.datasets import CUB\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 128\n",
    "n_workers = 0\n",
    "\n",
    "train_set = CUB(split=\"train\", training=True)\n",
    "train_loader = DataLoader(\n",
    "    train_set,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=n_workers,\n",
    "    pin_memory=True,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T09:39:41.151970Z",
     "start_time": "2024-06-23T09:39:41.002527Z"
    },
    "id": "-zNE9ffbqnpA",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from easyfsl.modules import resnet12\n",
    "\n",
    "DEVICE = \"cpu\"\n",
    "\n",
    "model = resnet12(\n",
    "    use_fc=True,\n",
    "    num_classes=len(set(train_set.get_labels())),\n",
    ").to(DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T09:46:34.684101Z",
     "start_time": "2024-06-23T09:46:34.547486Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DrUD75fEqnpC",
    "outputId": "fb3cd669-7cbb-40c8-9059-3ba359c96ac9",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from easyfsl.methods import PrototypicalNetworks,RelationNetworks,MatchingNetworks\n",
    "from easyfsl.samplers import TaskSampler\n",
    "\n",
    "n_way = 5\n",
    "n_shot = 5\n",
    "n_query = 10\n",
    "n_validation_tasks = 500\n",
    "\n",
    "val_set = CUB(split=\"val\", training=False)\n",
    "val_sampler = TaskSampler(\n",
    "    val_set, n_way=n_way, n_shot=n_shot, n_query=n_query, n_tasks=n_validation_tasks\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_set,\n",
    "    batch_sampler=val_sampler,\n",
    "    num_workers=n_workers,\n",
    "    pin_memory=True,\n",
    "    collate_fn=val_sampler.episodic_collate_fn,\n",
    ")\n",
    "\n",
    "# 根据主干的输出特征维度改变feature_dimension\n",
    "few_shot_classifier = MatchingNetworks(feature_dimension=640,backbone=model).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T09:46:43.596439Z",
     "start_time": "2024-06-23T09:46:42.910437Z"
    },
    "id": "59DHe5LBqnpE",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from torch.optim import SGD, Optimizer\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "LOSS_FUNCTION = nn.CrossEntropyLoss()\n",
    "\n",
    "n_epochs = 200\n",
    "scheduler_milestones = [150, 180]\n",
    "scheduler_gamma = 0.1\n",
    "learning_rate = 1e-01\n",
    "tb_logs_dir = Path(\".\")\n",
    "\n",
    "train_optimizer = SGD(\n",
    "    model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=5e-4\n",
    ")\n",
    "train_scheduler = MultiStepLR(\n",
    "    train_optimizer,\n",
    "    milestones=scheduler_milestones,\n",
    "    gamma=scheduler_gamma,\n",
    ")\n",
    "\n",
    "tb_writer = SummaryWriter(log_dir=str(tb_logs_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T09:46:47.194821Z",
     "start_time": "2024-06-23T09:46:47.184763Z"
    },
    "id": "NxMeTTCwqnpF",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def training_epoch(model_: nn.Module, data_loader: DataLoader, optimizer: Optimizer):\n",
    "    all_loss = []\n",
    "    model_.train()\n",
    "    with tqdm(data_loader, total=len(data_loader), desc=\"Training\") as tqdm_train:\n",
    "        for images, labels in tqdm_train:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss = LOSS_FUNCTION(model_(images.to(DEVICE)), labels.to(DEVICE))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            all_loss.append(loss.item())\n",
    "\n",
    "            tqdm_train.set_postfix(loss=mean(all_loss))\n",
    "\n",
    "    return mean(all_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T09:47:17.585235Z",
     "start_time": "2024-06-23T09:46:51.225744Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QEm3sKqPqnpG",
    "outputId": "680e0012-3e7b-470d-f800-cbd75e41f773",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████| 65/65 [06:36<00:00,  6.09s/it, loss=4.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                               | 0/65 [00:05<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[11], line 9\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(n_epochs):\n\u001B[1;32m      8\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEpoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m----> 9\u001B[0m     average_loss \u001B[38;5;241m=\u001B[39m \u001B[43mtraining_epoch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_optimizer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     11\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m epoch \u001B[38;5;241m%\u001B[39m validation_frequency \u001B[38;5;241m==\u001B[39m validation_frequency \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m     12\u001B[0m \n\u001B[1;32m     13\u001B[0m         \u001B[38;5;66;03m# We use this very convenient method from EasyFSL's ResNet to specify\u001B[39;00m\n\u001B[1;32m     14\u001B[0m         \u001B[38;5;66;03m# that the model shouldn't use its last fully connected layer during validation.\u001B[39;00m\n\u001B[1;32m     15\u001B[0m         model\u001B[38;5;241m.\u001B[39mset_use_fc(\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "Cell \u001B[0;32mIn[10], line 9\u001B[0m, in \u001B[0;36mtraining_epoch\u001B[0;34m(model_, data_loader, optimizer)\u001B[0m\n\u001B[1;32m      6\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m      8\u001B[0m loss \u001B[38;5;241m=\u001B[39m LOSS_FUNCTION(model_(images\u001B[38;5;241m.\u001B[39mto(DEVICE)), labels\u001B[38;5;241m.\u001B[39mto(DEVICE))\n\u001B[0;32m----> 9\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     10\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m     12\u001B[0m all_loss\u001B[38;5;241m.\u001B[39mappend(loss\u001B[38;5;241m.\u001B[39mitem())\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.10/site-packages/torch/_tensor.py:488\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    478\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    479\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    480\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    481\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    486\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[1;32m    487\u001B[0m     )\n\u001B[0;32m--> 488\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    489\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[1;32m    490\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.10/site-packages/torch/autograd/__init__.py:197\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    192\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    194\u001B[0m \u001B[38;5;66;03m# The reason we repeat same the comment below is that\u001B[39;00m\n\u001B[1;32m    195\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    196\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 197\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    198\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    199\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from easyfsl.utils import evaluate\n",
    "\n",
    "\n",
    "best_state = model.state_dict()\n",
    "best_validation_accuracy = 0.0\n",
    "validation_frequency = 10\n",
    "for epoch in range(n_epochs):\n",
    "    print(f\"Epoch {epoch}\")\n",
    "    average_loss = training_epoch(model, train_loader, train_optimizer)\n",
    "\n",
    "    if epoch % validation_frequency == validation_frequency - 1:\n",
    "\n",
    "        # We use this very convenient method from EasyFSL's ResNet to specify\n",
    "        # that the model shouldn't use its last fully connected layer during validation.\n",
    "        model.set_use_fc(False)\n",
    "        validation_accuracy = evaluate(\n",
    "            few_shot_classifier, val_loader, device=DEVICE, tqdm_prefix=\"Validation\"\n",
    "        )\n",
    "        model.set_use_fc(True)\n",
    "\n",
    "        if validation_accuracy > best_validation_accuracy:\n",
    "            best_validation_accuracy = validation_accuracy\n",
    "            best_state = copy.deepcopy(few_shot_classifier.state_dict())\n",
    "            # state_dict() returns a reference to the still evolving model's state so we deepcopy\n",
    "            # https://pytorch.org/tutorials/beginner/saving_loading_models\n",
    "            print(\"Ding ding ding! We found a new best model!\")\n",
    "\n",
    "        tb_writer.add_scalar(\"Val/acc\", validation_accuracy, epoch)\n",
    "\n",
    "    tb_writer.add_scalar(\"Train/loss\", average_loss, epoch)\n",
    "\n",
    "    # Warn the scheduler that we did an epoch\n",
    "    # so it knows when to decrease the learning rate\n",
    "    train_scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T09:47:20.249221Z",
     "start_time": "2024-06-23T09:47:20.217833Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EG9bBTz4qnpH",
    "outputId": "f4aed221-a7fc-4563-d51c-d6606fd704ac",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(best_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T09:47:22.362690Z",
     "start_time": "2024-06-23T09:47:22.202813Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eveON7-wqnpI",
    "outputId": "14f75db7-8395-4019-ef4a-73d8ce72bca9",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n_test_tasks = 1000\n",
    "\n",
    "test_set = CUB(split=\"test\", training=False)\n",
    "test_sampler = TaskSampler(\n",
    "    test_set, n_way=n_way, n_shot=n_shot, n_query=n_query, n_tasks=n_test_tasks\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_set,\n",
    "    batch_sampler=test_sampler,\n",
    "    num_workers=n_workers,\n",
    "    pin_memory=True,\n",
    "    collate_fn=test_sampler.episodic_collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T09:47:26.418536Z",
     "start_time": "2024-06-23T09:47:24.781460Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lK6WOtpwqnpJ",
    "outputId": "89f92fcd-c8b5-4bda-d1b7-294ccfaf19c0",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                       | 0/1000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected feature dimension is 140, but got 640.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[14], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m model\u001B[38;5;241m.\u001B[39mset_use_fc(\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m----> 3\u001B[0m accuracy \u001B[38;5;241m=\u001B[39m \u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfew_shot_classifier\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mDEVICE\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAverage accuracy : \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m(\u001B[38;5;241m100\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;250m \u001B[39maccuracy)\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.2f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m %\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m/ML/Mashuai/few-shot-learning/easyfsl/utils.py:149\u001B[0m, in \u001B[0;36mevaluate\u001B[0;34m(model, data_loader, device, use_tqdm, tqdm_prefix)\u001B[0m\n\u001B[1;32m    136\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tqdm(\n\u001B[1;32m    137\u001B[0m     \u001B[38;5;28menumerate\u001B[39m(data_loader),\n\u001B[1;32m    138\u001B[0m     total\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mlen\u001B[39m(data_loader),\n\u001B[1;32m    139\u001B[0m     disable\u001B[38;5;241m=\u001B[39m\u001B[38;5;129;01mnot\u001B[39;00m use_tqdm,\n\u001B[1;32m    140\u001B[0m     desc\u001B[38;5;241m=\u001B[39mtqdm_prefix,\n\u001B[1;32m    141\u001B[0m ) \u001B[38;5;28;01mas\u001B[39;00m tqdm_eval:\n\u001B[1;32m    142\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m _, (\n\u001B[1;32m    143\u001B[0m         support_images,\n\u001B[1;32m    144\u001B[0m         support_labels,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    147\u001B[0m         _,\n\u001B[1;32m    148\u001B[0m     ) \u001B[38;5;129;01min\u001B[39;00m tqdm_eval:\n\u001B[0;32m--> 149\u001B[0m         correct, total \u001B[38;5;241m=\u001B[39m \u001B[43mevaluate_on_one_task\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    150\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[43m            \u001B[49m\u001B[43msupport_images\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    152\u001B[0m \u001B[43m            \u001B[49m\u001B[43msupport_labels\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    153\u001B[0m \u001B[43m            \u001B[49m\u001B[43mquery_images\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    154\u001B[0m \u001B[43m            \u001B[49m\u001B[43mquery_labels\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    155\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    157\u001B[0m         total_predictions \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m total\n\u001B[1;32m    158\u001B[0m         correct_predictions \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m correct\n",
      "File \u001B[0;32m/ML/Mashuai/few-shot-learning/easyfsl/utils.py:100\u001B[0m, in \u001B[0;36mevaluate_on_one_task\u001B[0;34m(model, support_images, support_labels, query_images, query_labels)\u001B[0m\n\u001B[1;32m     89\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mevaluate_on_one_task\u001B[39m(\n\u001B[1;32m     90\u001B[0m     model: FewShotClassifier,\n\u001B[1;32m     91\u001B[0m     support_images: Tensor,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     94\u001B[0m     query_labels: Tensor,\n\u001B[1;32m     95\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[\u001B[38;5;28mint\u001B[39m, \u001B[38;5;28mint\u001B[39m]:\n\u001B[1;32m     96\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     97\u001B[0m \u001B[38;5;124;03m    Returns the number of correct predictions of query labels, and the total number of\u001B[39;00m\n\u001B[1;32m     98\u001B[0m \u001B[38;5;124;03m    predictions.\u001B[39;00m\n\u001B[1;32m     99\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 100\u001B[0m     \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprocess_support_set\u001B[49m\u001B[43m(\u001B[49m\u001B[43msupport_images\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msupport_labels\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    101\u001B[0m     predictions \u001B[38;5;241m=\u001B[39m model(query_images)\u001B[38;5;241m.\u001B[39mdetach()\u001B[38;5;241m.\u001B[39mdata\n\u001B[1;32m    102\u001B[0m     number_of_correct_predictions \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(\n\u001B[1;32m    103\u001B[0m         (torch\u001B[38;5;241m.\u001B[39mmax(predictions, \u001B[38;5;241m1\u001B[39m)[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m==\u001B[39m query_labels)\u001B[38;5;241m.\u001B[39msum()\u001B[38;5;241m.\u001B[39mitem()\n\u001B[1;32m    104\u001B[0m     )\n",
      "File \u001B[0;32m/ML/Mashuai/few-shot-learning/easyfsl/methods/matching_networks.py:89\u001B[0m, in \u001B[0;36mMatchingNetworks.process_support_set\u001B[0;34m(self, support_images, support_labels)\u001B[0m\n\u001B[1;32m     79\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     80\u001B[0m \u001B[38;5;124;03mOverrides process_support_set of FewShotClassifier.\u001B[39;00m\n\u001B[1;32m     81\u001B[0m \u001B[38;5;124;03mExtract features from the support set with full context embedding.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     86\u001B[0m \u001B[38;5;124;03m    support_labels: labels of support set images of shape (n_support, )\u001B[39;00m\n\u001B[1;32m     87\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     88\u001B[0m support_features \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompute_features(support_images)\n\u001B[0;32m---> 89\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_features_shape\u001B[49m\u001B[43m(\u001B[49m\u001B[43msupport_features\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     90\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontextualized_support_features \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mencode_support_features(\n\u001B[1;32m     91\u001B[0m     support_features\n\u001B[1;32m     92\u001B[0m )\n\u001B[1;32m     94\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mone_hot_support_labels \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m     95\u001B[0m     nn\u001B[38;5;241m.\u001B[39mfunctional\u001B[38;5;241m.\u001B[39mone_hot(  \u001B[38;5;66;03m# pylint: disable=not-callable\u001B[39;00m\n\u001B[1;32m     96\u001B[0m         support_labels\n\u001B[1;32m     97\u001B[0m     )\u001B[38;5;241m.\u001B[39mfloat()\n\u001B[1;32m     98\u001B[0m )\n",
      "File \u001B[0;32m/ML/Mashuai/few-shot-learning/easyfsl/methods/matching_networks.py:197\u001B[0m, in \u001B[0;36mMatchingNetworks._validate_features_shape\u001B[0;34m(self, features)\u001B[0m\n\u001B[1;32m    195\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_raise_error_if_features_are_multi_dimensional(features)\n\u001B[1;32m    196\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m features\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfeature_dimension:\n\u001B[0;32m--> 197\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    198\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExpected feature dimension is \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfeature_dimension\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, but got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfeatures\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    199\u001B[0m     )\n",
      "\u001B[0;31mValueError\u001B[0m: Expected feature dimension is 140, but got 640."
     ]
    }
   ],
   "source": [
    "model.set_use_fc(False)\n",
    "\n",
    "accuracy = evaluate(few_shot_classifier, test_loader, device=DEVICE)\n",
    "print(f\"Average accuracy : {(100 * accuracy):.2f} %\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "classical_training.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
